{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentmint Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this notebook, data will be loaded and preprocced then it will be trained on LSTM layers to analyse twitter sentment reasons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Contents \n",
    " - [Required modules](#Required%modules)\n",
    " - [loading data](#loading%data)\n",
    " - [Data analysis](#Data%analysis)\n",
    " - [Data encoding](#Data%encoding)\n",
    " - [Data decoding](#Data%decoding)\n",
    " - [Match length and strat index ](#Match%length%and%strat%index)\n",
    " - [Data masking](#Data%masking)\n",
    " - [Un-Mask data](#Un-Mask%data)\n",
    " - [Preparing training and validation data](#Preparing%training%and%validation%data)\n",
    " - [Defining the model](#Defining%the%model)\n",
    " - [Model parameters count](#Model%parameters%count)\n",
    " - [Hyperparameter](#Hyperparameter)\n",
    " - [Instantiate model](#Instantiate%model)\n",
    " - [Test forward function](#Test%forward%function)\n",
    " - [Optimizer and criterion](#Optimizer%and%criterion)\n",
    " - [Train function](#Train%function)\n",
    " - [Saving model](#Saving%model)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter majec function to print images inlined\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import matplotlib.pyplot as plt # ploting.\n",
    "import seaborn as sns # more cool plotting \n",
    "from nltk.corpus import stopwords # load stoping words\n",
    "from nltk.tokenize import word_tokenize # word tokenizer\n",
    "import operator\n",
    "from itertools import chain \n",
    "from math import floor\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "import re # Regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data of shape (27486, 4)\n",
      "Test data of shape (3535, 3)\n"
     ]
    }
   ],
   "source": [
    "dataPath = 'dataset'\n",
    "\n",
    "#Training data\n",
    "train = pd.read_csv(dataPath+'/train.csv')\n",
    "# Testing data \n",
    "test = pd.read_csv(dataPath+'/test.csv')\n",
    "\n",
    "for col in train.columns:\n",
    "    train[col] = train[col].astype(str)\n",
    "for col in test.columns:\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "print(\"Train data of shape\",train.shape)\n",
    "print(\"Test data of shape\",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data first 10 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f14f087215</td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1915bebcb3</td>\n",
       "      <td>headache  wanna see my Julie</td>\n",
       "      <td>headache</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2ab82634d5</td>\n",
       "      <td>had an awsome salad! I recommend getting the Spicey buffalo chicken salad!</td>\n",
       "      <td>had an awsome salad!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>a5a1c996c0</td>\n",
       "      <td>fine! Going to do my big walk today 20 or so miles</td>\n",
       "      <td>fine!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>a182b2638e</td>\n",
       "      <td>Thank a yoou  how are you? #TwitterTakeover</td>\n",
       "      <td>Thank</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1dcb6fdb13</td>\n",
       "      <td>Why don't adobe realise no one WANTS to pay for Photoshop et al so they should just give it to us for free</td>\n",
       "      <td>Why don't adobe realise no one WANTS to pay for Photoshop et al so they should just give it to us for free</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  a3d0a7d5ad   \n",
       "1  251b6a6766   \n",
       "2  c9e8d1ef1c   \n",
       "3  f14f087215   \n",
       "4  bf7473b12d   \n",
       "5  1915bebcb3   \n",
       "6  2ab82634d5   \n",
       "7  a5a1c996c0   \n",
       "8  a182b2638e   \n",
       "9  1dcb6fdb13   \n",
       "\n",
       "                                                                                                                                   text  \\\n",
       "0  Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning   \n",
       "1   Oh! Good idea about putting them on ice cream                                                                                         \n",
       "2  says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj                                                                  \n",
       "3   i dont think you can vote anymore! i tried                                                                                            \n",
       "4   haha better drunken tweeting you mean?                                                                                                \n",
       "5  headache  wanna see my Julie                                                                                                           \n",
       "6  had an awsome salad! I recommend getting the Spicey buffalo chicken salad!                                                             \n",
       "7   fine! Going to do my big walk today 20 or so miles                                                                                    \n",
       "8   Thank a yoou  how are you? #TwitterTakeover                                                                                           \n",
       "9  Why don't adobe realise no one WANTS to pay for Photoshop et al so they should just give it to us for free                             \n",
       "\n",
       "                                                                                                selected_text  \\\n",
       "0  my boss was not happy w/ them. Lots of fun.                                                                  \n",
       "1  Good                                                                                                         \n",
       "2  says good (or should i say bad?) afternoon!                                                                  \n",
       "3  i dont think you can vote anymore!                                                                           \n",
       "4  better                                                                                                       \n",
       "5  headache                                                                                                     \n",
       "6  had an awsome salad!                                                                                         \n",
       "7  fine!                                                                                                        \n",
       "8  Thank                                                                                                        \n",
       "9  Why don't adobe realise no one WANTS to pay for Photoshop et al so they should just give it to us for free   \n",
       "\n",
       "  sentiment  \n",
       "0  neutral   \n",
       "1  positive  \n",
       "2  neutral   \n",
       "3  negative  \n",
       "4  positive  \n",
       "5  negative  \n",
       "6  positive  \n",
       "7  positive  \n",
       "8  positive  \n",
       "9  neutral   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data sample\n",
    "elements_from_head=10 # number of elements to show from head\n",
    "\n",
    "print(\"Train data first\", elements_from_head, \"samples\")\n",
    "train.head(elements_from_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data first 10 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11aa4945ff</td>\n",
       "      <td>http://twitpic.com/67swx - i wish i was calling you but i can't from Malta</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>fd1db57dc0</td>\n",
       "      <td>i'm done.haha. HOUSE MD marathon ulet</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2524332d66</td>\n",
       "      <td>I'm concerned for that family</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0fb19285b2</td>\n",
       "      <td>HEY GUYS IT'S WORKING NO NEED TO WORRY. i have tooo many followers tho ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>e6c9e5e3ab</td>\n",
       "      <td>26th February</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>311d2b185b</td>\n",
       "      <td>Tracy and Berwick breaks my achy breaky heart  They split ways in the hallways.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>95dfefd4e7</td>\n",
       "      <td>Well off 2 bed...cant wait 2 party 4 Mother's Day in like 14 hours or so</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>739f17cfe1</td>\n",
       "      <td>Oh yeah the camera clipping problems with Void are now completely fixed  yay me for fiddling about</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>c6322a85c2</td>\n",
       "      <td>_Layne  hmm.. what's ur fav movie?? tv shows??</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>b4401d6b4d</td>\n",
       "      <td>salt and vinegar, cheese and onion make your breathe smell lol  ****</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  11aa4945ff   \n",
       "1  fd1db57dc0   \n",
       "2  2524332d66   \n",
       "3  0fb19285b2   \n",
       "4  e6c9e5e3ab   \n",
       "5  311d2b185b   \n",
       "6  95dfefd4e7   \n",
       "7  739f17cfe1   \n",
       "8  c6322a85c2   \n",
       "9  b4401d6b4d   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "0   http://twitpic.com/67swx - i wish i was calling you but i can't from Malta                          \n",
       "1  i'm done.haha. HOUSE MD marathon ulet                                                                \n",
       "2   I'm concerned for that family                                                                       \n",
       "3  HEY GUYS IT'S WORKING NO NEED TO WORRY. i have tooo many followers tho ...                           \n",
       "4   26th February                                                                                       \n",
       "5  Tracy and Berwick breaks my achy breaky heart  They split ways in the hallways.                      \n",
       "6  Well off 2 bed...cant wait 2 party 4 Mother's Day in like 14 hours or so                             \n",
       "7  Oh yeah the camera clipping problems with Void are now completely fixed  yay me for fiddling about   \n",
       "8  _Layne  hmm.. what's ur fav movie?? tv shows??                                                       \n",
       "9   salt and vinegar, cheese and onion make your breathe smell lol  ****                                \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  positive  \n",
       "4  neutral   \n",
       "5  negative  \n",
       "6  positive  \n",
       "7  positive  \n",
       "8  neutral   \n",
       "9  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data sample\n",
    "\n",
    "print(\"Test data first\", elements_from_head, \"samples\")\n",
    "test.head(elements_from_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "Number of positive is 11118, number of negative is 8582, and number of neutral is 7786\n",
      "Train Data Sentiment\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos,neg,nat=train['sentiment'].value_counts()\n",
    "\n",
    "print(\"Training data\")\n",
    "print(\"Number of positive is {}, number of negative is {}, and number of neutral is {}\".format(pos,neg,nat))\n",
    "sns.countplot(x='sentiment',data=train)\n",
    "print(\"Train Data Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('in', 3556), ('for', 3575), ('is', 3670), ('you', 3808), ('i', 4264), ('and', 4677), ('my', 4932), ('a', 6503), ('the', 8391), ('I', 8802)]\n"
     ]
    }
   ],
   "source": [
    "def word_frequency(data,return_word_frequency):\n",
    "    for word in data.split():\n",
    "        if return_word_frequency.get(word, False): return_word_frequency[word]+=1\n",
    "        else: return_word_frequency[word]=1\n",
    "    return return_word_frequency\n",
    "\n",
    "\n",
    "train_text_freq={}\n",
    "for i in train.text:\n",
    "    train_count_freq = word_frequency(i,train_text_freq)\n",
    "    \n",
    "# train_text_freq = train_df.text.apply(lambda x : word_frequency(x,train_text_freq) )\n",
    "\n",
    "sorted_train_text_freq = sorted(train_text_freq.items(), key=operator.itemgetter(1))\n",
    "print(sorted_train_text_freq[-11:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character one hot encodings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotBase=np.zeros(256)\n",
    "\n",
    "def oneHot(i):\n",
    "    cop=np.copy(oneHotBase)\n",
    "    cop[i]=1\n",
    "    return cop \n",
    "chr2vec={chr(i): oneHot(i) for i in range(256)}\n",
    "\n",
    "\n",
    "def encode(text):\n",
    "    ln = len(text)\n",
    "    a= np.fromiter(chain.from_iterable(chr2vec[text[x2]] for x2 in range(len(text))), 'i', len(text) * 256)\n",
    "    a.shape = len(text), 256\n",
    "#   a= np.empty((ln, 256), int) # (text, 265)\n",
    "#   for i in range(ln):\n",
    "#       a[i]=chr2vec[text[i]]\n",
    "#       [chr2vec[text[i]] for i in range(ln)]\n",
    "    x = np.zeros((280-len(text),256)) #(text,256)\n",
    "    \n",
    "    return np.concatenate((a, x), axis=0)\n",
    "\n",
    "\n",
    "train_encoded=train.copy()\n",
    "train_encoded.text=train.text.apply(lambda x:encode(x))\n",
    "train_encoded.selected_text=train.selected_text.apply(lambda x:encode(x))\n",
    "\n",
    "\n",
    "test_encoded=test.copy()\n",
    "test_encoded.text=test.text.apply(lambda x:encode(x))\n",
    "\n",
    "print(\"Finished encoding\")\n",
    "train_encoded.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2Chr(lst):\n",
    "    for x in range(len(lst)): \n",
    "        if lst[x] == 1: return chr(x)\n",
    "\n",
    "def vecs2String(lst):\n",
    "    string=\"\"\n",
    "    for i in lst:\n",
    "        if i == oneHotBase: break\n",
    "        string+=vec2Chr(i)\n",
    "    return string\n",
    "\n",
    "print(\"Decode(train_encoded.text[0]) is: \\n\",vecs2String(train_encoded.text[0]))\n",
    "print(\"=================\")\n",
    "\n",
    "\n",
    "do_assert = 1\n",
    "if do_assert:\n",
    "    assert(vec2Chr(chr2vec['a']) == 'a') \n",
    "    assert(vecs2String(train_encoded.text[0]) == train.text[0]) \n",
    "    \n",
    "print(\"Finished decoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match length and strat index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done match_length Calc.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>match_length</th>\n",
       "      <th>start_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f14f087215</td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  a3d0a7d5ad   \n",
       "1  251b6a6766   \n",
       "2  c9e8d1ef1c   \n",
       "3  f14f087215   \n",
       "4  bf7473b12d   \n",
       "\n",
       "                                                                                                                                   text  \\\n",
       "0  Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning   \n",
       "1   Oh! Good idea about putting them on ice cream                                                                                         \n",
       "2  says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj                                                                  \n",
       "3   i dont think you can vote anymore! i tried                                                                                            \n",
       "4   haha better drunken tweeting you mean?                                                                                                \n",
       "\n",
       "                                 selected_text sentiment  match_length  \\\n",
       "0  my boss was not happy w/ them. Lots of fun.  neutral   43             \n",
       "1  Good                                         positive  4              \n",
       "2  says good (or should i say bad?) afternoon!  neutral   43             \n",
       "3  i dont think you can vote anymore!           negative  34             \n",
       "4  better                                       positive  6              \n",
       "\n",
       "   start_index  \n",
       "0  55           \n",
       "1  5            \n",
       "2  0            \n",
       "3  1            \n",
       "4  6            "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"match_length\"]=train.apply(lambda x : len(x.selected_text), axis=1)\n",
    "train[\"start_index\"]=train.apply(lambda x : x.text.find(x.selected_text), axis=1)\n",
    "\n",
    "print(\"Done match_length Calc.\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>match_length</th>\n",
       "      <th>start_index</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f14f087215</td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  a3d0a7d5ad   \n",
       "1  251b6a6766   \n",
       "2  c9e8d1ef1c   \n",
       "3  f14f087215   \n",
       "4  bf7473b12d   \n",
       "\n",
       "                                                                                                                                   text  \\\n",
       "0  Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning   \n",
       "1   Oh! Good idea about putting them on ice cream                                                                                         \n",
       "2  says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj                                                                  \n",
       "3   i dont think you can vote anymore! i tried                                                                                            \n",
       "4   haha better drunken tweeting you mean?                                                                                                \n",
       "\n",
       "                                 selected_text sentiment  match_length  \\\n",
       "0  my boss was not happy w/ them. Lots of fun.  neutral   43             \n",
       "1  Good                                         positive  4              \n",
       "2  says good (or should i say bad?) afternoon!  neutral   43             \n",
       "3  i dont think you can vote anymore!           negative  34             \n",
       "4  better                                       positive  6              \n",
       "\n",
       "   start_index  \\\n",
       "0  55            \n",
       "1  5             \n",
       "2  0             \n",
       "3  1             \n",
       "4  6             \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       masks  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]  \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]  \n",
       "3  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask(original, subtext, match_length, start_index):\n",
    "    msk=np.zeros(len(original))\n",
    "    msk[start_index:start_index+match_length]+=1\n",
    "    return msk\n",
    "\n",
    "def padding(lst):\n",
    "    return np.append(lst, np.array([0]*(280-len(lst))))\n",
    "    \n",
    "masks = (train.apply(lambda x : mask(x.text, x.selected_text, x.match_length, x.start_index), axis=1)).apply(\n",
    "        lambda x : padding(x))\n",
    "train[\"masks\"]=masks\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-Mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_mask(string, mask): \n",
    "    return ''.join([string[i] for i in range(len(mask)) if int(mask[i]) == 1])\n",
    "\n",
    "un_masked = train.apply(lambda x: un_mask(x.text,x.masks), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.random' has no attribute 'default_rng'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3b8aa404e4ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvalidation_data_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'default_rng'"
     ]
    }
   ],
   "source": [
    "validation_data_size= floor(train.shape[0])*(10/100)\n",
    "idx= (np.random.default_rng()).choice(train.shape(0), size=validation_data_size, replace=False)\n",
    "validation_data= train[idx]\n",
    "\n",
    "train.drop(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, LSTM_hidden_size, LTSM_num_layers, hidden_layers,\n",
    "                 LSTM_dropout, batch_first=True, output_size=1, drop_p=0.5):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = input_size,\n",
    "                            hidden_size = LSTM_hidden_size,\n",
    "                            num_layers = LTSM_num_layers,\n",
    "                            batch_first = batch_first,\n",
    "                            dropout = LSTM_dropout,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "        \n",
    "        # Add the first layer, input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(LSTM_hidden_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        # \n",
    "        x = F.tanh(self.lstm(x))\n",
    "\n",
    "        # Forward through each layer in `hidden_layers`, with ReLU activation and dropout\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters for model_1 is  2741575\n",
      "Trainable parameters for model_2 is  1164615\n",
      "Trainable parameters for model_3 is  1131365\n",
      "Trainable parameters for model_4 is  302851\n",
      "Trainable parameters for model_5 is  544451\n",
      "Trainable parameters for model_6 is  1722451\n",
      "Trainable parameters for model_7 is  1722451\n",
      "Trainable parameters for model_8 is  4238643\n",
      "Trainable parameters for model_9 is  5815603\n",
      "Trainable parameters for model_10 is  7392563\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "input_size, LSTM_hidden_size, LTSM_num_layers, hidden_layers,\n",
    "LSTM_dropout, batch_first=True, output_size=1, drop_p=0.5)\n",
    "'''\n",
    "model_1 = Network(256, 256, 2, [256,150,50],\n",
    "               0.1, True, 1, 0.2)\n",
    "\n",
    "model_2 = Network(256, 256, 1, [256,150,50],\n",
    "               0.1, True, 1, 0.2)\n",
    "\n",
    "model_3 = Network(256, 256, 1, [256,50],\n",
    "               0.1, True, 1, 0.2)\n",
    "\n",
    "model_4 = Network(256, 100, 1, [100,50,25],\n",
    "               0.1, True, 1, 0.2)\n",
    "\n",
    "model_5 = Network(256, 100, 2, [100,50,25],\n",
    "               0.1, True, 1, 0.2)\n",
    "\n",
    "model_6 = Network(256, 200, 2, [100,50,25],\n",
    "               0.1, True, 1, 0.2)\n",
    "\n",
    "model_7 = Network(256, 200, 2, [100,50,25],\n",
    "               0.9, True, 1, 0.9)\n",
    "\n",
    "model_8 = Network(256, 256, 3, [100,50,25],\n",
    "               0.9, True, 1, 0.9)\n",
    "\n",
    "model_9 = Network(256, 256, 4, [100,50,25],\n",
    "               0.9, True, 1, 0.9)\n",
    "\n",
    "model_10 = Network(256, 256, 5, [100,50,25],\n",
    "               0.9, True, 1, 0.9)\n",
    "\n",
    "print(\"Trainable parameters for model_1 is \", sum(p.numel() for p in model_1.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_2 is \", sum(p.numel() for p in model_2.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_3 is \", sum(p.numel() for p in model_3.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_4 is \", sum(p.numel() for p in model_4.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_5 is \", sum(p.numel() for p in model_5.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_6 is \", sum(p.numel() for p in model_6.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_7 is \", sum(p.numel() for p in model_7.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_8 is \", sum(p.numel() for p in model_8.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_9 is \", sum(p.numel() for p in model_9.parameters() if p.requires_grad))\n",
    "print(\"Trainable parameters for model_10 is \", sum(p.numel() for p in model_10.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "input_size= 256\n",
    "LSTM_hidden_size= 256\n",
    "LTSM_num_layers= 2\n",
    "hidden_layers= [256,150,50]\n",
    "LSTM_dropout= 0.1\n",
    "batch_first=True\n",
    "output_size=1\n",
    "drop_p=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(input_size, LSTM_hidden_size, LTSM_num_layers, hidden_layers, LSTM_dropout,\n",
    "                batch_first, output_size, drop_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "    \n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for tweet, result in trainloader:\n",
    "            steps += 1\n",
    "            \n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(tweet)\n",
    "            loss = criterion(output, results)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
